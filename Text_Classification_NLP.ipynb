{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3506fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.probability import FreqDist\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e84c7",
   "metadata": {},
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf1c13e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50425"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"ecommerceDataset.csv\", names=[\"labels\", \"descriptions\"]) # reading the dataset \n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b91e43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "descriptions = df[\"descriptions\"].map(str).values.tolist() # taking out the descriptions and making as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1d35100",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"labels\"].values.tolist() # taking out the labels and making as list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912d3caf",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24deda5c",
   "metadata": {},
   "source": [
    "Changing the descriptions into lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b57760",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = [(str(df[\"descriptions\"][i]).lower(),df[\"labels\"][i]) for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3021fbc5",
   "metadata": {},
   "source": [
    "Creating a function to Tokenize the given string and remove the stopwords and finally returns count of the root words after stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1681b347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will do\n",
    "# 1. tokenization - breaking the string into words\n",
    "# 2. remove stopwords - remvoes the unwanted words\n",
    "# 3. stemming - gives the root word\n",
    "\n",
    "def preprocess(a):\n",
    "    tokens = word_tokenize(a)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    ps = PorterStemmer()\n",
    "    tokens_ = [ps.stem(i) for i in tokens if i not in stop_words]\n",
    "    return FreqDist(tokens_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66498a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set = [(preprocess(i),j) for (i,j) in data] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59bec1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(feature_set) #shuffles all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44eee80",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a52fb9",
   "metadata": {},
   "source": [
    "Dividing the data into\n",
    "Train Data - 75%\n",
    "Test Data - 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcce9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = feature_set[:int(0.75*len(data))],feature_set[int(0.25*len(data)):] # divides the training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49d05afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(train) # Creating a navie bayes model and training the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de965cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using Naive bayes :  0.954202913879267\n"
     ]
    }
   ],
   "source": [
    "accuracy = nltk.classify.accuracy(clf,test) # returns the accuracy of test data\n",
    "print(\"Accuracy using Naive bayes : \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf7b634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saf 'floral' framed painting (wood, 30 inch x 10 inch, special effect uv print textured, sao297) painting made up in synthetic frame with uv textured print which gives multi effects and attracts towards it. this is an special series of paintings which makes your wall very beautiful and gives a royal touch (a perfect gift for your special ones). \n",
      "\n",
      "Household\n"
     ]
    }
   ],
   "source": [
    "print(data[1][0],\"\\n\")\n",
    "print(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91089ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicition is Correct\n"
     ]
    }
   ],
   "source": [
    "# verifing by giving one description from dataset \n",
    "pred = clf.classify(preprocess(data[1][0]))\n",
    "if pred == data[1][1]:\n",
    "    print(\"Predicition is Correct\")\n",
    "else:\n",
    "    print(\"Wrong Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce15d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
